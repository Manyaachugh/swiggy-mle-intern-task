{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8GAD1_v0pmc",
        "outputId": "4897aac7-9b39-4803-92d5-6c96a00ef9d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Precision    Recall  F1-Score   ROC-AUC\n",
            "Logistic Regression   0.878788  0.717314  0.789883  0.980630\n",
            "XGBoost               1.000000  1.000000  1.000000  1.000000\n",
            "SVM                   0.948276  0.971731  0.959860  0.999359\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "model_files = {\n",
        "    \"Logistic Regression\": \"metrics_LR.json\",\n",
        "    \"XGBoost\": \"metrics_XGBoost.json\",\n",
        "    \"SVM\": \"metrics_SVM.json\"\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for model_name, file in model_files.items():\n",
        "    with open(file, \"r\") as f:\n",
        "        results[model_name] = json.load(f)\n",
        "\n",
        "# Create comparison table\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" I trained three models - logistic regression, XGBoost and SVM on the given restaurant review dataset to predict the risk label.\n",
        "It can be clearly seen that Xgboost outperformed and achieved a perfect score with all metrics equal to 1.0, reason most likely\n",
        "being its ability to capture non-linear interactions and ability to handle class imbalance(which can be seen in our dataset{safe\n",
        "restaurants heavily outnumber risky restaurants } Although perfect metrics on a test set may indicate overfitting specially if the\n",
        "dataset is small or not very diverse, But for now it can be concluded that XGBoost performed excellent on this dataset, real world\n",
        "validation is recommended.)\n",
        "SVM also performed really well with an f1-score of 0.96 and ROC-AUC of 0.99. Logistic Regression performed decently but had a lower\n",
        "recall of 0.72, thus, it may have missed some high-risk restaurants.\n",
        "Based on these results, XGBoost is the best choice for deployment and further explainability analysis.\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "PuERSS4Z3saX",
        "outputId": "7671c665-7c54-45a2-a57e-1db3644ca634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' I trained three models - logistic regression, XGBoost and SVM on the given restaurant review dataset to predict the risk label.\\nIt can be clearly seen that Xgboost outperformed and achieved a perfect score with all metrics equal to 1.0, reason most likely\\nbeing its ability to capture non-linear interactions and ability to handle class imbalance(which can be seen in our dataset{safe \\nrestaurants heavily outnumber risky restaurants } Although perfect metrics on a test set may indicate overfitting specially if the \\ndataset is small or not very diverse, But for now it can be concluded that XGBoost performed excellent on this dataset, real world\\nvalidation is recommended.) \\nSVM also performed really well with an f1-score of 0.96 and ROC-AUC of 0.99. Logistic Regression performed decently but had a lower \\nrecall of 0.72, thus, it may have missed some high-risk restaurants. \\nBased on these results, XGBoost is the best choice for deployment and further explainability analysis.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BeoHng_S4m7d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}